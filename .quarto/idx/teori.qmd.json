{"title":"Teori","markdown":{"yaml":{"title":"Teori","format":"pdf"},"headingText":"Linjär regression","containsRefs":false,"markdown":"\n\nLinjär regression används för att undersöka sambandet mellan en beroende variabel ($Y$) och en eller flera oberoende variabler ($X$).\n\nDet finns två typer:\n\n- Enkel linjär regression, där det finns en oberoende variabel.\n\n- Multipel linjär regression, där det finns flera oberoende variabler.\n\nEnkel linjär regression skrivs som:\n$$\ny = \\beta_0 + \\beta_1 x + \\varepsilon\n$$\n\nMultipel linjär regression skrivs som:\n\n$$\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_p x_p + \\varepsilon\n$$\n\n(Prgomet, 2024)\n\n## Prediktorer och responsvariabel\nPrediktorerna $(X)$ är de olika variabler vi använder i modellen. Exempel på sådana variabler är lön, utbildning och ålder. Responsvariabeln $(Y)$ även kallad målvariabeln är den vi vill förutsäga med hjälp av variablerna $X$. Enligt samma exempel så skulle detta vara lön.\n\nNär modellen tränas så beräknas en koefficient för varje enskild variabel $X$, vilket representerar hur mycket just den variabeln påverkar $Y$ (Prgomet, 2024).\n\n## R² och justerat R²\n\"Visar hur stor andel av variationen i den oberoende variabeln $Y$ som kan förklaras med sambandet av den oberoede variabeln $X$\"(Prgomet, 2024, s. 9). Värdet ligger mellan 0 och 1.\n\nJusterat R² används för att justera måttet när man har flera prediktorer då måttet annars skulle öka för varje ny prediktor som adderas (Prgomet, 2024).\n\n$$\nR^2 = 1 - \\frac{\\text{RSS}}{\\text{TSS}}\n$$\n\n\n$$\nR^2_{\\text{adj}} = 1 - \\left( \\frac{(1 - R^2)(n - 1)}{n - p - 1} \\right)\n$$\n\n## RMSE\nRMSE används för att mäta medelfelet i modellens prediktioner. Det mäter avståndet mellan de faktiska värdena och de predikterade värdena (Prgomet, 2024).\n$$\n\\text{RMSE} = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 }\n$$\n\n## BIC\nBIC är ett mått som används för att jämföra olika modeller. Det tar hänsyn till både hur bra modellen passar datan och hur komplex modellen är. Ett lågt BIC indikerar en bättre modell. Måttet straffar modeller med många prediktorer, särskilt vid större datamängder, vilket är väligt användbart för att undvika överanpassning (James, Witten, Hastie & Tibshirani, 2023, s. 324).\n\n$$\n\\text{BIC} = \\frac{\\text{RSS}}{n \\cdot \\hat{\\sigma}^2} + \\log(n) \\cdot d\n$$\n\n## P-värde och hypotesprövning\n### P-värde\nP-värdet visar hur troligt det är att ett samband mellan en variabel och $Y$ uppstått av en slump.\nEtt lågt p-värde tyder på att sambandet är verkligt och inte bara tillfälligt (James, Witten, Hastie & Tibshirani, 2023, s. 68).\n\n### Hyppotesprövnning\nVi testar om en variabel påverkar $Y$ genom att jämföra två hypoteser:\n- Nollhypotes ($H_0$): Ingen påverkan (koefficienten = 0)\n- Mothypotes ($H_1$): Variabeln påverkar $Y$\n\nOm p-värdet är lågt (t.ex. < 0,05) förkastar vi nollhypotesen och säger att sambandet är signifikant (Prgomet, 2024).\n\n## Dummyvariabler\nNär kategoriska variabler används i en linjär regressionsmodell omvandlas de automatiskt till så kallade dummyvariabler.\nDet innebär att varje kategori blir en egen binär (0 eller 1) kolumn, vilket gör det möjligt att använda dem som numeriska prediktorer i modellen (Prgomet, 2024).\n\n## Multikollinearitet & VIF\nMultikollinearitet uppstår när två eller flera prediktorer i modellen är starkt korrelerade med varandra. Det kan göra det svårt att avgöra vilken variabel som faktiskt påverkar $Y$, eftersom deras effekter \"överlappar\".\nFör att upptäcka multikollinearitet används bland annat VIF (Variance Inflation Factor). Ett högt VIF-värde (t.ex. över 5 eller 10) kan tyda på problem med multikollinearitet (Prgomet, 2024).\n\n## Best Subset Selection\nBest Subset Selection är en metod för att hitta den bästa modellen med ett visst antal prediktorer. Genom att jämföra alla möjliga kombinationer väljs den modell som ger bäst prestanda enligt mått som t.ex. justerat R² eller BIC (James, Witten, Hastie & Tibshirani, 2023, s. 227).\n\n## Antaganden i linjär regression\n### Normalfördelade residualer\nFör att få pålitlig inferens som konfidensintervall förutästter det att vi har normalfördelade residualer. Om residualerna inte är normalfördelade kan man undersöka om det exempelvis finns outliers i datan som påverkar fördelningen (Prgomet, 2024).\n\n### Linjärt samband mellan X och Y\nEnkel- eller multipel regression bygger på att det finns ett linjärt samband mellan den oberoende variabeln $X$ och den beroende varibeln $Y$. Finns det inget linjärt samband så kan vi inte lita på prediktioner eller inferens. För att undersöka sambandet kan man visualisera residualerna (Prgomet, 2024).\n\n### Homoskedasticitet (konstant varians)\nVid beräkning av standardavikelse för beta koefficienterna och predikterade värden, antas att variansen är homogen, det vill säga konstant. Annars har vi heteroskedasticitet, vilket innebär att prediktioner och inferens blir fel (Prgomet, 2024).\n\n### Oberoende residualer\nResidualerna i en regressionsmodell förutsätts vara oberoende av varandra, vilket innebär att feltermerna inte får vara korrelerade. Detta är särskilt viktigt i tidsserieanalys (Prgomet, 2024). I detta arbete är datan inte tidsberoende, och därför har detta antagande inte undersökts i detalj.\n\n### Outliers/high leverage\nOutliers är observerade värden som ligger längre eller långt bort från det uppskattade värdet. High leverage innebär att dessa värden kan ha en stor eller större påverkan på modellen. Det är därför bra praxis att studera om det finns outliers i datan och eventuellt hantera dessa (Prgomet, 2024).\n\n\n## Konfidens- och prediktionsintervall\n### Konfidensintervall\nKonfidensintervallet uppskattar hur säkra vi är på det förväntade medelvärdet för $Y$. Det ger ett intervall med ett undre och ett övre värde där vi förväntar oss att det sanna medelvärdet ligger (Prgomet, 2024).\n\n### Prediktionsintervall\nPrediktionsintervallet är alltid bredare än konfidensintervallet, eftersom det även tar hänsyn till feltermen ($\\varepsilon$) – alltså den slumpmässiga variationen vid en ny observation. Det speglar osäkerheten i själva observationen, inte bara medelvärdet (Prgomet, 2024).","srcMarkdownNoYaml":"\n\n## Linjär regression\nLinjär regression används för att undersöka sambandet mellan en beroende variabel ($Y$) och en eller flera oberoende variabler ($X$).\n\nDet finns två typer:\n\n- Enkel linjär regression, där det finns en oberoende variabel.\n\n- Multipel linjär regression, där det finns flera oberoende variabler.\n\nEnkel linjär regression skrivs som:\n$$\ny = \\beta_0 + \\beta_1 x + \\varepsilon\n$$\n\nMultipel linjär regression skrivs som:\n\n$$\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_p x_p + \\varepsilon\n$$\n\n(Prgomet, 2024)\n\n## Prediktorer och responsvariabel\nPrediktorerna $(X)$ är de olika variabler vi använder i modellen. Exempel på sådana variabler är lön, utbildning och ålder. Responsvariabeln $(Y)$ även kallad målvariabeln är den vi vill förutsäga med hjälp av variablerna $X$. Enligt samma exempel så skulle detta vara lön.\n\nNär modellen tränas så beräknas en koefficient för varje enskild variabel $X$, vilket representerar hur mycket just den variabeln påverkar $Y$ (Prgomet, 2024).\n\n## R² och justerat R²\n\"Visar hur stor andel av variationen i den oberoende variabeln $Y$ som kan förklaras med sambandet av den oberoede variabeln $X$\"(Prgomet, 2024, s. 9). Värdet ligger mellan 0 och 1.\n\nJusterat R² används för att justera måttet när man har flera prediktorer då måttet annars skulle öka för varje ny prediktor som adderas (Prgomet, 2024).\n\n$$\nR^2 = 1 - \\frac{\\text{RSS}}{\\text{TSS}}\n$$\n\n\n$$\nR^2_{\\text{adj}} = 1 - \\left( \\frac{(1 - R^2)(n - 1)}{n - p - 1} \\right)\n$$\n\n## RMSE\nRMSE används för att mäta medelfelet i modellens prediktioner. Det mäter avståndet mellan de faktiska värdena och de predikterade värdena (Prgomet, 2024).\n$$\n\\text{RMSE} = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 }\n$$\n\n## BIC\nBIC är ett mått som används för att jämföra olika modeller. Det tar hänsyn till både hur bra modellen passar datan och hur komplex modellen är. Ett lågt BIC indikerar en bättre modell. Måttet straffar modeller med många prediktorer, särskilt vid större datamängder, vilket är väligt användbart för att undvika överanpassning (James, Witten, Hastie & Tibshirani, 2023, s. 324).\n\n$$\n\\text{BIC} = \\frac{\\text{RSS}}{n \\cdot \\hat{\\sigma}^2} + \\log(n) \\cdot d\n$$\n\n## P-värde och hypotesprövning\n### P-värde\nP-värdet visar hur troligt det är att ett samband mellan en variabel och $Y$ uppstått av en slump.\nEtt lågt p-värde tyder på att sambandet är verkligt och inte bara tillfälligt (James, Witten, Hastie & Tibshirani, 2023, s. 68).\n\n### Hyppotesprövnning\nVi testar om en variabel påverkar $Y$ genom att jämföra två hypoteser:\n- Nollhypotes ($H_0$): Ingen påverkan (koefficienten = 0)\n- Mothypotes ($H_1$): Variabeln påverkar $Y$\n\nOm p-värdet är lågt (t.ex. < 0,05) förkastar vi nollhypotesen och säger att sambandet är signifikant (Prgomet, 2024).\n\n## Dummyvariabler\nNär kategoriska variabler används i en linjär regressionsmodell omvandlas de automatiskt till så kallade dummyvariabler.\nDet innebär att varje kategori blir en egen binär (0 eller 1) kolumn, vilket gör det möjligt att använda dem som numeriska prediktorer i modellen (Prgomet, 2024).\n\n## Multikollinearitet & VIF\nMultikollinearitet uppstår när två eller flera prediktorer i modellen är starkt korrelerade med varandra. Det kan göra det svårt att avgöra vilken variabel som faktiskt påverkar $Y$, eftersom deras effekter \"överlappar\".\nFör att upptäcka multikollinearitet används bland annat VIF (Variance Inflation Factor). Ett högt VIF-värde (t.ex. över 5 eller 10) kan tyda på problem med multikollinearitet (Prgomet, 2024).\n\n## Best Subset Selection\nBest Subset Selection är en metod för att hitta den bästa modellen med ett visst antal prediktorer. Genom att jämföra alla möjliga kombinationer väljs den modell som ger bäst prestanda enligt mått som t.ex. justerat R² eller BIC (James, Witten, Hastie & Tibshirani, 2023, s. 227).\n\n## Antaganden i linjär regression\n### Normalfördelade residualer\nFör att få pålitlig inferens som konfidensintervall förutästter det att vi har normalfördelade residualer. Om residualerna inte är normalfördelade kan man undersöka om det exempelvis finns outliers i datan som påverkar fördelningen (Prgomet, 2024).\n\n### Linjärt samband mellan X och Y\nEnkel- eller multipel regression bygger på att det finns ett linjärt samband mellan den oberoende variabeln $X$ och den beroende varibeln $Y$. Finns det inget linjärt samband så kan vi inte lita på prediktioner eller inferens. För att undersöka sambandet kan man visualisera residualerna (Prgomet, 2024).\n\n### Homoskedasticitet (konstant varians)\nVid beräkning av standardavikelse för beta koefficienterna och predikterade värden, antas att variansen är homogen, det vill säga konstant. Annars har vi heteroskedasticitet, vilket innebär att prediktioner och inferens blir fel (Prgomet, 2024).\n\n### Oberoende residualer\nResidualerna i en regressionsmodell förutsätts vara oberoende av varandra, vilket innebär att feltermerna inte får vara korrelerade. Detta är särskilt viktigt i tidsserieanalys (Prgomet, 2024). I detta arbete är datan inte tidsberoende, och därför har detta antagande inte undersökts i detalj.\n\n### Outliers/high leverage\nOutliers är observerade värden som ligger längre eller långt bort från det uppskattade värdet. High leverage innebär att dessa värden kan ha en stor eller större påverkan på modellen. Det är därför bra praxis att studera om det finns outliers i datan och eventuellt hantera dessa (Prgomet, 2024).\n\n\n## Konfidens- och prediktionsintervall\n### Konfidensintervall\nKonfidensintervallet uppskattar hur säkra vi är på det förväntade medelvärdet för $Y$. Det ger ett intervall med ett undre och ett övre värde där vi förväntar oss att det sanna medelvärdet ligger (Prgomet, 2024).\n\n### Prediktionsintervall\nPrediktionsintervallet är alltid bredare än konfidensintervallet, eftersom det även tar hänsyn till feltermen ($\\varepsilon$) – alltså den slumpmässiga variationen vid en ny observation. Det speglar osäkerheten i själva observationen, inte bara medelvärdet (Prgomet, 2024)."},"formats":{"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":true,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","toc":true,"number-sections":true,"include-in-header":["preamble.tex"],"output-file":"teori.pdf"},"language":{"toc-title-document":"Innehållsförteckning","toc-title-website":"På denna sida","related-formats-title":"Andra Format","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Källa","other-links-title":"Övriga länkar","code-links-title":"Kodlänkar","launch-dev-container-title":"Starta Dev Container","launch-binder-title":"Starta Binder","article-notebook-label":"Artikelanteckningsbok","notebook-preview-download":"Ladda ner anteckningsbok","notebook-preview-download-src":"Ladda ner källkod","notebook-preview-back":"Tillbaka till artikel","manuscript-meca-bundle":"MECA-arkiv","section-title-abstract":"Sammanfattning","section-title-appendices":"Bilagor","section-title-footnotes":"Fotnot","section-title-references":"Referenser","section-title-reuse":"Återanvänd","section-title-copyright":"Copyright","section-title-citation":"Citat","appendix-attribution-cite-as":"Hänvisa till detta arbete som:","appendix-attribution-bibtex":"BibTeX hänvisning:","appendix-view-license":"Visa Licens","title-block-author-single":"Författare","title-block-author-plural":"Författare","title-block-affiliation-single":"Anknuten","title-block-affiliation-plural":"Anknutna","title-block-published":"Utgiven","title-block-modified":"Ändrad","title-block-keywords":"Nyckelord","callout-tip-title":"Tips","callout-note-title":"Notera","callout-warning-title":"Varning","callout-important-title":"Viktigt","callout-caution-title":"Caution","code-summary":"Kod","code-tools-menu-caption":"Kod","code-tools-show-all-code":"Visa all kod","code-tools-hide-all-code":"Göm all kod","code-tools-view-source":"Visa källa","code-tools-source-code":"Källkod","tools-share":"Share","tools-download":"Download","code-line":"Rad","code-lines":"Rader","copy-button-tooltip":"Kopiera till urklipp","copy-button-tooltip-success":"Kopierat!","repo-action-links-edit":"Redigera denna sida","repo-action-links-source":"Visa källa","repo-action-links-issue":"Rapportera ett problem","back-to-top":"Tillbaka till toppen","search-no-results-text":"Inget resultat","search-matching-documents-text":"matchande dokument","search-copy-link-title":"Kopiera länk för att söka","search-hide-matches-text":"Göm ytterligare resultat","search-more-match-text":"annat resultat i detta dokument","search-more-matches-text":"fler resultat i detta dokument","search-clear-button-title":"Rensa","search-text-placeholder":"","search-detached-cancel-button-title":"Avbryt","search-submit-button-title":"Verkställ","search-label":"Sök","toggle-section":"Skifta sektion","toggle-sidebar":"Skifta sidonavigering","toggle-dark-mode":"Skifta mörkt läge","toggle-reader-mode":"Skifta läsläge","toggle-navigation":"Skifta navigering","crossref-fig-title":"Figur","crossref-tbl-title":"Tabell","crossref-lst-title":"Lista","crossref-thm-title":"Teorem","crossref-lem-title":"Lemma","crossref-cor-title":"Följdsats","crossref-prp-title":"Påstående","crossref-cnj-title":"Förmodan","crossref-def-title":"Definition","crossref-exm-title":"Exempel","crossref-exr-title":"Uppgift","crossref-ch-prefix":"Kapitel","crossref-apx-prefix":"Bilaga","crossref-sec-prefix":"Avsnitt","crossref-eq-prefix":"Ekvation","crossref-lof-title":"Figurförteckning","crossref-lot-title":"Tabellförteckning","crossref-lol-title":"Listförteckning","environment-proof-title":"Bevis","environment-remark-title":"Anmärkning","environment-solution-title":"Lösning","listing-page-order-by":"Sorterat efter","listing-page-order-by-default":"Standard","listing-page-order-by-date-asc":"Äldst","listing-page-order-by-date-desc":"Nyast","listing-page-order-by-number-desc":"Högt till lågt","listing-page-order-by-number-asc":"Lågt till högt","listing-page-field-date":"Datum","listing-page-field-title":"Titel","listing-page-field-description":"Beskrivning","listing-page-field-author":"Författare","listing-page-field-filename":"Filnamn","listing-page-field-filemodified":"Ändrad","listing-page-field-subtitle":"Undertitel","listing-page-field-readingtime":"Lästid","listing-page-field-wordcount":"Ordmätning","listing-page-field-categories":"Kategorier","listing-page-minutes-compact":"{0} min","listing-page-category-all":"Allt","listing-page-no-matches":"Inget resultat","listing-page-words":"{0} ord","listing-page-filter":"Filter","draft":"Utkast"},"metadata":{"block-headings":true,"lang":"sv","title":"Teori"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["pdf"]}