{"title":"Resultat och diskussion","markdown":{"yaml":{"title":"Resultat och diskussion","format":"pdf"},"headingText":"Resultat","containsRefs":false,"markdown":"\n### Resultat efter träning\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#rm(list = ls())\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(glue)\nload(\"data/data_volvo_prepared.RData\")\n```\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Checking all is ok with data before split.\nnames(data)\nsummary(data)\ndim(data)\ncolSums(is.na(data))\n```\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#No use for orig_row anymore, and i dont want models to train on it. So i drop it.\ndata <- data |>\n    select(-orig_row)\nnames(data)\ndim(data)\n```\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Splitng data so i can train, val and test the moodels.\nspec = c(train = .6, validate = .2, test = .2)\n\nset.seed(123)\ng = sample(cut(\n  seq(nrow(data)), \n  nrow(data)*cumsum(c(0, spec)),\n  labels = names(spec)\n))\n\nres = split(data, g)\n\ntrain <- res$train\nval   <- res$validate\ntest  <- res$test\n```\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Checking the split was successful.\ndim(train)\ndim(val)\ndim(test)\n```\n\n#### Resultat Modell 1 - Alla prediktorer\nDen första modellen som tränats är en multipel regressionsmodell med samtliga tillgängliga prediktorer. Eftersom modellens output var omfattande valde jag att enbart redovisa de mest centrala måtten.\nResultatet visade:\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Training with all variables to see which ones affect or not.\nmodel_1 <- lm(price ~ ., data=train)\n```\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\nmodel_1_summary <-summary(model_1)\nmodel_1_summary\n```\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\nlibrary(car)\n#vif(model_1) #Remove \"#\" to run code. Puttiinig # so i can continue running the code.  \nmm <- model.matrix(price ~ ., data = train) # Checking which dummy variables were generated from categorical predictors\n\ncolnames(mm)\n```\n\n- **R²:** 0.9175\n- **Justerat R²:** 0.9040\n- **Residual standard error (RSE):** 53 626\n- **F-statistic:** 67.93 (df = 75, 458), p-värde < 2.2e-16\n\nDetta innebar att modellen förklarade över 91 % av variationen i bilpriset, vilket var ett mycket gott resultat.\n\nTvå variabler kunde inte uppskattas i modellen. Mer om detta går att läsa i avsnittet ”Undersökning av teoretiska antaganden”.\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\nalias(model_1)\ntable(train$model == \"C70\")\ntable(train$region == \"Örebro\")\n```\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Droping color and region as it's not significant in the model.\ncol_drop <- c(\"color\", \"region\")\n\ntrain <- train |> select(-all_of(col_drop))\nval <- val |> select(-all_of(col_drop))\ntest <- test |> select(-all_of(col_drop))\nnames(train) # Checking to se if columns were dropped.\n```\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Retraining the model with the new data to see how it performs now.\nmodel_1 <- lm(price ~ ., data = train)\nmodel_1_summary <- summary(model_1)\nmodel_1_summary\n```\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Still problem with singularity. To few observations for C70. Need to count how many\n# observation there is total for this model\ndata |>\n  filter(model == \"C70\") |>\n  count()\n```\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Removing C70 due to problem with to few observations.\ntrain <- train |> filter(model != \"C70\")\nval   <- val   |> filter(model != \"C70\")\ntest  <- test  |> filter(model != \"C70\")\n```\n\n#### Resultat Modell 1 – Justerade prediktorer\n\nModellen tränades på hela det rensade träningsdatasetet med samtliga prediktorer (utom `color`, `region` och `model == \"C70\"`). \nResultatet visade:\n\n- **R²:** 0.9105\n- **Justerat R²:** 0.9023\n- **Residual standard error (RSE):** 54 120\n- **F-statistic:** 110.1 (df = 45, 487), p-värde < 2.2e-16\n\nModellen visade hög förklaringsgrad och god modellanpassning. Inga problem med singulariteter eller multikollinearitet identifierades.\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\nmodel_1 <- lm(price ~ ., data = train)\nmodel_1_sum <- summary(model_1)\nvif(model_1)\n```\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\nmodel_2 <- lm(price ~ year_model + miles + hpower, data = train)\nmodel_2_sum <- summary(model_2)\nmodel_2_sum\nvif(model_2)\n```\n\n#### Resultat Modell 2\nDen andra modellen tränades med endast tre prediktorer: year_model, miles och hpower. Detta var i linje med syftet att hitta en enklare modell.\n\n- **R²:** 0.8191\n- **Justerat R²:** 0.8181\n- **Residual standard error (RSE):** (RSE): 73 830\n- **F-statistic:** 798.4 (df = 3, 529), p-värde < 2.2e-16\n\nVid kontroll av multikollinearitet med vif() visade samtliga prediktorer låga värden:\n\nyear_model ≈ 2.19\nmiles ≈ 2.06\nhpower ≈ 1.42\n\nDetta indikerar att modellen inte led av multikollinearitet.\n\n#### Resultat Modell 3 (Subset Selection)\nBest Subset Selection testades på samtliga 11 prediktorer för att identifiera den bästa modellen med få prediktorer. Den modell som gav högst justerat R² innehöll följande fyra variabler: year_model, miles, hpower och modelEX90.\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#install.packages(\"leaps\")\nlibrary(leaps)\ndim(train) #Checking value of predictors so i know how many nvmax i need to choose.\nmodel_3 <- regsubsets(price ~ ., data = train, nvmax = 11)\nmodel_3_sum <- summary(model_3)\nmodel_3_sum\n```\n\n\n```{r}\n#| echo: false\n#| fig-cap: \"Justerat R² för olika antal prediktorer. Brytpunkten där modellen slutar ge tydlig förbättring bedöms vara vid fyra prediktorer. Den fjärde variabeln var dock en specifik bilmodell (EX90), vilket ansågs vara för snävt för en generell modell och valdes därför bort.\"\nplot(model_3_sum$adjr2, type = \"b\", xlab = \"Antal prediktorer\", ylab = \"Justerat R²\")\n```\n\n\n```{r}\n#| echo: false\n#| #| results: \"hide\"\n#| warning: false\ncoef(model_3, 4)\n```\n\nEftersom modelEX90 endast representerar en enskild bilmodell, och målet var att ta fram en generell modell, valdes den bort. I stället prövades en ny modell där fuel (t.ex. El, Hybrid) användes som fjärde prediktor då tidigare EDA visat skillnader i pris mellan bränsletyper.\n\nResultat för denna justerade modell presenteras i nästa avsnitt.\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\nmodel_3 <- lm(price ~ fuel + year_model + miles + hpower, data = train)\nmodel_3_sum <- summary(model_3)\nmodel_3_sum\n```\n\n#### Resultat Modell 3 - 4 prediktorer\n\nDen tredje modellen tränades med prediktorerna fuel, year_model, miles och hpower, där fuel användes för att särskilja mellan förbränningsmotorer och el-/hybridbilar.\n\n- **R²:** 0.8241\n- **Justerat R²:** 0.8218\n- **Residual standard error (RSE):** 73 080\n- **F-statistic:** 351.4 (df = 7, 525), p-värde < 2.2e-16\n\n### Resultat efter validering\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n# Some model values (e.g. \"850\") were not present in the training data, which caused an error.\n# To enable validation, I remove any values in val/test that were not seen during training.\nval <- val |> filter(model %in% unique(train$model))\ntest <- test |> filter(model %in% unique(train$model))\n```\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\nval_pred_m1 <- predict(model_1, newdata = val)\nval_pred_m2 <- predict(model_2, newdata = val)\nval_pred_m3 <- predict(model_3, newdata = val)\n```\n\n\n```{r}\n#| echo: false\n#| #| warning: false\nlibrary(Metrics)  # rmse()\n\nresults <- data.frame(\n  Model = c(\"Model 1\", \"Model 2\", \"Model 3\"),\n  RMSE_val = c(rmse(val$price, val_pred_m1),\n               rmse(val$price, val_pred_m2),\n               rmse(val$price, val_pred_m3)),\n  Adjusted_R2 = c(summary(model_1)$adj.r.squared,\n                  summary(model_2)$adj.r.squared,\n                  summary(model_3)$adj.r.squared),\n  BIC = c(BIC(model_1), BIC(model_2), BIC(model_3))\n)\n\nresults\n```\n\n#### Jämförelse av modeller\nValideringsresultaten visade följande prestanda för de tre modellerna:\n\n| Modell   | RMSE (val-data) | Justerat R² | BIC      |\n|----------|------------------|--------------|----------|\n| Modell 1 | 51 361           | 0.902        | 13 378   |\n| Modell 2 | 73 575           | 0.818        | 13 489   |\n| Modell 3 | 73 022           | 0.822        | 13 500   |\n\nModell 1 hade lägst RMSE, högst justerat R² och lägst BIC, vilket indikerade bäst prestanda totalt sett. Däremot innehöll den flest prediktorer, vilket kan göra modellen mer komplex och svårtolkad i praktisk användning.\n\nEftersom syftet var att bygga en så **enkel modell som möjligt** utan att förlora alltför mycket precision, var även **modell 2 och 3** mycket relevanta alternativ. Dessa modeller presterade på en jämförbar nivå men med endast tre till fyra prediktorer. Det gjorde dem bättre lämpade för prediktion i ett praktiskt sammanhang där tillgången till variabler kan vara begränsade.\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Saving model to use in undersokning_antaganden.qmd\nsaveRDS(model_3, file = \"model/model_3.rds\")\n```\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Saving train data for use in undersokning_antaganden.qmd\nsaveRDS(train, file = \"data/train_ua.rds\")\n```\n\n### Modellens prestanda på testdata\nSom slutlig modell valdes modell 3. Den testades slutligen på tesdtatan.\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\ntest_pred <- predict(model_3, newdata = test)\ntest_rmse <- rmse(test$price, test_pred)\ntest_rmse\n```\n\nDen uppnådde ett RMSE på cirka **139 500 kr**, vilket gav en uppfattning om hur mycket de faktiska priserna i genomsnitt skiljde sig från modellens predikterade värden.\n\nDetta innebar att modellen kan ge en relativt god prisuppskattning, men att osäkerheten ökar vid högre prisklasser, vilket också observerats i tidigare analyser.\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n# Checking data for expensive cars.\ntrain |> filter(price > 1000000)\nval   |> filter(price > 1000000)\ntest  |> filter(price > 1000000)\n```\n\nEftersom några enstaka bilar i träningsdatan kostade över en miljon kronor, undersöktes om sådana fanns i test- eller valideringsdata. Då inga högprisfordon förekom i testdatan, kan RMSE-värdet underskatta osäkerheten vid prediktion av mycket dyra bilar.\n\n#### Testar modellen med en ny observation\nJag ville nu testa modellens förmåga att prediktera priset för en bil. Jag letade upp en riktig bilannons på blocket och matade in alla värden förutom pris. \n\nBilen hade följande specifikationer:\nBränsle: Diesel\nÅrsmodell: 2018\nMiltal: 14 610\nHästkrafter: 191\nPris i annonsen: 221 800 kr\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\nnew_car <- data.frame(\n  fuel = \"Diesel\",\n  year_model = 2018,\n  miles = 14610,\n  hpower = 191\n)\n```\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\nconfidence_intervals <- predict(model_3, newdata = new_car, interval = \"confidence\", level = 0.95)\nprediction_intervals <- predict(model_3, newdata = new_car, interval = \"prediction\", level = 0.95)\nconfidence_intervals\nprediction_intervals\n```\n\n\n```{r}\n#| echo: false\ndata.frame(\n  Estimate = prediction_intervals[1],\n  CI_Lower = confidence_intervals[2],\n  CI_Upper = confidence_intervals[3],\n  PI_Lower = prediction_intervals[2],\n  PI_Upper = prediction_intervals[3]\n)\n```\n\nPriset i annonsen låg utanför konfidensintervallet men inom prediktionsintervallet, vilket var väntat. Det innebar att priset ligger inom det spann som modellen anser möjligt för enskilda observationer, även om det är något lägre än det förväntade medelvärdet. Den breda spridningen i prediktionsintervallet visade att osäkerheten var större vid enskilda observationer, vilket är normalt i regressionsanalys.\n\n## Diskussion\n### Val av modell och måluppfyllelse\nI arbetet tränades tre modeller med olika antal prediktorer, vilka utvärderades på valideringsdatan. Modell 1 innehöll samtliga tillgängliga prediktorer och hade den högsta förklaringsgraden (adjusted R² ≈ 0,90), medan modell 2 och 3 bestod av färre variabler men uppnådde ändå ett justerat R² kring 0,82.\n\nEftersom målet var att utveckla en så enkel modell som möjligt med bibehållen god förklaringsgrad, valdes modell 3 som slutlig modell. Denna hade fyra prediktorer och bedömdes ge tillräcklig precision samtidigt som den var enklare att använda i praktiken.\n\n### Modellens begränsningar och valda förenklingar\nI modellen har flera faktorer som i verkligheten kan påverka priset valts bort – exempelvis extrautrustning, färg och region. Detta var ett medvetet val i syfte att förenkla modellen och minska brus. Till skillnad från exempelvis bostadsmarknaden, där läge och utseende har stor påverkan, tenderade faktorer som färg eller geografiskt läge inte att vara signifikanta för bilpris i detta dataset. Det kan bero på att bilar är flyttbara och konsumenter är villiga att resa för att köpa rätt bil – därmed påverkade inte platsen priset i samma utsträckning.\n\n### Generaliseringsförmåga och hantering av extrema värden\nFör att förbättra modellens generaliseringsförmåga hade det varit möjligt att:\n\n- Filtrera bort extremt dyra bilar (outliers), vilket skulle ha gjort residualerna mer normalfördelade och minskat osäkerheten vid prediktion.\n\n- Samla in fler observationer av dyrare bilar, vilket hade gett en mer balanserad datamängd och bättre prediktion i de högre prisklasserna.\n\nI detta arbete valdes dock att behålla de extrema värdena. Dels av tidsbrist, men även för att undersöka hur modellen skulle bete sig med sådan data, vilket gav viktiga insikter inför framtida modellering.\n\n### Modellens prestanda och praktisk tillämpning\nModellen presterade bra. På valideringsdatan låg RMSE runt 70 000 kr, och på testdatan ungefär 140 000 kr. Den ökade osäkerheten i testdatan kan bero på att det inte fanns några riktigt dyra bilar där, till skillnad från träningsdatan. Det tyder på att modellen funkar bra för vanliga bilar men får svårare med lyxsegmentet – vilket är rimligt.\n\nFör att testa modellen i praktiken gjordes en prediktion på en riktig annons från Blocket: en dieselbil från 2018 med 14 610 mil och 191 hk. Modellen förutsåg priset till 247 387 kr, jämfört med annonspriset 221 800 kr – en skillnad på ca 25 000 kr. Det får ändå anses vara en träffsäker uppskattning med tanke på marknadens variationer.\n\nSpridningen i prediktionsintervallet förklaras delvis av att datan inte var helt normalfördelad – det fanns några bilar med väldigt höga priser. Jag hade kunnat transformera datan eller ta bort outliers, men valde att behålla dem för att se hur modellen funkar i praktiken även för lite mer extrema priser. Trots detta ger modellen en tillräckligt bra uppskattning, särskilt för vanligare biltyper.\n\n### Sammanfattning\nSyftet var att undersöka om en enkel modell med få prediktorer kunde ge en tillräckligt god förklaring av bilpriser – något som uppnåddes. Genom att gå från en komplex till en praktiskt användbar modell med fyra prediktorer, har arbetet visat att det är möjligt att förenkla utan att förlora allt för mycket precision.","srcMarkdownNoYaml":"\n## Resultat\n### Resultat efter träning\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#rm(list = ls())\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(glue)\nload(\"data/data_volvo_prepared.RData\")\n```\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Checking all is ok with data before split.\nnames(data)\nsummary(data)\ndim(data)\ncolSums(is.na(data))\n```\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#No use for orig_row anymore, and i dont want models to train on it. So i drop it.\ndata <- data |>\n    select(-orig_row)\nnames(data)\ndim(data)\n```\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Splitng data so i can train, val and test the moodels.\nspec = c(train = .6, validate = .2, test = .2)\n\nset.seed(123)\ng = sample(cut(\n  seq(nrow(data)), \n  nrow(data)*cumsum(c(0, spec)),\n  labels = names(spec)\n))\n\nres = split(data, g)\n\ntrain <- res$train\nval   <- res$validate\ntest  <- res$test\n```\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Checking the split was successful.\ndim(train)\ndim(val)\ndim(test)\n```\n\n#### Resultat Modell 1 - Alla prediktorer\nDen första modellen som tränats är en multipel regressionsmodell med samtliga tillgängliga prediktorer. Eftersom modellens output var omfattande valde jag att enbart redovisa de mest centrala måtten.\nResultatet visade:\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Training with all variables to see which ones affect or not.\nmodel_1 <- lm(price ~ ., data=train)\n```\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\nmodel_1_summary <-summary(model_1)\nmodel_1_summary\n```\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\nlibrary(car)\n#vif(model_1) #Remove \"#\" to run code. Puttiinig # so i can continue running the code.  \nmm <- model.matrix(price ~ ., data = train) # Checking which dummy variables were generated from categorical predictors\n\ncolnames(mm)\n```\n\n- **R²:** 0.9175\n- **Justerat R²:** 0.9040\n- **Residual standard error (RSE):** 53 626\n- **F-statistic:** 67.93 (df = 75, 458), p-värde < 2.2e-16\n\nDetta innebar att modellen förklarade över 91 % av variationen i bilpriset, vilket var ett mycket gott resultat.\n\nTvå variabler kunde inte uppskattas i modellen. Mer om detta går att läsa i avsnittet ”Undersökning av teoretiska antaganden”.\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\nalias(model_1)\ntable(train$model == \"C70\")\ntable(train$region == \"Örebro\")\n```\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Droping color and region as it's not significant in the model.\ncol_drop <- c(\"color\", \"region\")\n\ntrain <- train |> select(-all_of(col_drop))\nval <- val |> select(-all_of(col_drop))\ntest <- test |> select(-all_of(col_drop))\nnames(train) # Checking to se if columns were dropped.\n```\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Retraining the model with the new data to see how it performs now.\nmodel_1 <- lm(price ~ ., data = train)\nmodel_1_summary <- summary(model_1)\nmodel_1_summary\n```\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Still problem with singularity. To few observations for C70. Need to count how many\n# observation there is total for this model\ndata |>\n  filter(model == \"C70\") |>\n  count()\n```\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Removing C70 due to problem with to few observations.\ntrain <- train |> filter(model != \"C70\")\nval   <- val   |> filter(model != \"C70\")\ntest  <- test  |> filter(model != \"C70\")\n```\n\n#### Resultat Modell 1 – Justerade prediktorer\n\nModellen tränades på hela det rensade träningsdatasetet med samtliga prediktorer (utom `color`, `region` och `model == \"C70\"`). \nResultatet visade:\n\n- **R²:** 0.9105\n- **Justerat R²:** 0.9023\n- **Residual standard error (RSE):** 54 120\n- **F-statistic:** 110.1 (df = 45, 487), p-värde < 2.2e-16\n\nModellen visade hög förklaringsgrad och god modellanpassning. Inga problem med singulariteter eller multikollinearitet identifierades.\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\nmodel_1 <- lm(price ~ ., data = train)\nmodel_1_sum <- summary(model_1)\nvif(model_1)\n```\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\nmodel_2 <- lm(price ~ year_model + miles + hpower, data = train)\nmodel_2_sum <- summary(model_2)\nmodel_2_sum\nvif(model_2)\n```\n\n#### Resultat Modell 2\nDen andra modellen tränades med endast tre prediktorer: year_model, miles och hpower. Detta var i linje med syftet att hitta en enklare modell.\n\n- **R²:** 0.8191\n- **Justerat R²:** 0.8181\n- **Residual standard error (RSE):** (RSE): 73 830\n- **F-statistic:** 798.4 (df = 3, 529), p-värde < 2.2e-16\n\nVid kontroll av multikollinearitet med vif() visade samtliga prediktorer låga värden:\n\nyear_model ≈ 2.19\nmiles ≈ 2.06\nhpower ≈ 1.42\n\nDetta indikerar att modellen inte led av multikollinearitet.\n\n#### Resultat Modell 3 (Subset Selection)\nBest Subset Selection testades på samtliga 11 prediktorer för att identifiera den bästa modellen med få prediktorer. Den modell som gav högst justerat R² innehöll följande fyra variabler: year_model, miles, hpower och modelEX90.\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#install.packages(\"leaps\")\nlibrary(leaps)\ndim(train) #Checking value of predictors so i know how many nvmax i need to choose.\nmodel_3 <- regsubsets(price ~ ., data = train, nvmax = 11)\nmodel_3_sum <- summary(model_3)\nmodel_3_sum\n```\n\n\n```{r}\n#| echo: false\n#| fig-cap: \"Justerat R² för olika antal prediktorer. Brytpunkten där modellen slutar ge tydlig förbättring bedöms vara vid fyra prediktorer. Den fjärde variabeln var dock en specifik bilmodell (EX90), vilket ansågs vara för snävt för en generell modell och valdes därför bort.\"\nplot(model_3_sum$adjr2, type = \"b\", xlab = \"Antal prediktorer\", ylab = \"Justerat R²\")\n```\n\n\n```{r}\n#| echo: false\n#| #| results: \"hide\"\n#| warning: false\ncoef(model_3, 4)\n```\n\nEftersom modelEX90 endast representerar en enskild bilmodell, och målet var att ta fram en generell modell, valdes den bort. I stället prövades en ny modell där fuel (t.ex. El, Hybrid) användes som fjärde prediktor då tidigare EDA visat skillnader i pris mellan bränsletyper.\n\nResultat för denna justerade modell presenteras i nästa avsnitt.\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\nmodel_3 <- lm(price ~ fuel + year_model + miles + hpower, data = train)\nmodel_3_sum <- summary(model_3)\nmodel_3_sum\n```\n\n#### Resultat Modell 3 - 4 prediktorer\n\nDen tredje modellen tränades med prediktorerna fuel, year_model, miles och hpower, där fuel användes för att särskilja mellan förbränningsmotorer och el-/hybridbilar.\n\n- **R²:** 0.8241\n- **Justerat R²:** 0.8218\n- **Residual standard error (RSE):** 73 080\n- **F-statistic:** 351.4 (df = 7, 525), p-värde < 2.2e-16\n\n### Resultat efter validering\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n# Some model values (e.g. \"850\") were not present in the training data, which caused an error.\n# To enable validation, I remove any values in val/test that were not seen during training.\nval <- val |> filter(model %in% unique(train$model))\ntest <- test |> filter(model %in% unique(train$model))\n```\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\nval_pred_m1 <- predict(model_1, newdata = val)\nval_pred_m2 <- predict(model_2, newdata = val)\nval_pred_m3 <- predict(model_3, newdata = val)\n```\n\n\n```{r}\n#| echo: false\n#| #| warning: false\nlibrary(Metrics)  # rmse()\n\nresults <- data.frame(\n  Model = c(\"Model 1\", \"Model 2\", \"Model 3\"),\n  RMSE_val = c(rmse(val$price, val_pred_m1),\n               rmse(val$price, val_pred_m2),\n               rmse(val$price, val_pred_m3)),\n  Adjusted_R2 = c(summary(model_1)$adj.r.squared,\n                  summary(model_2)$adj.r.squared,\n                  summary(model_3)$adj.r.squared),\n  BIC = c(BIC(model_1), BIC(model_2), BIC(model_3))\n)\n\nresults\n```\n\n#### Jämförelse av modeller\nValideringsresultaten visade följande prestanda för de tre modellerna:\n\n| Modell   | RMSE (val-data) | Justerat R² | BIC      |\n|----------|------------------|--------------|----------|\n| Modell 1 | 51 361           | 0.902        | 13 378   |\n| Modell 2 | 73 575           | 0.818        | 13 489   |\n| Modell 3 | 73 022           | 0.822        | 13 500   |\n\nModell 1 hade lägst RMSE, högst justerat R² och lägst BIC, vilket indikerade bäst prestanda totalt sett. Däremot innehöll den flest prediktorer, vilket kan göra modellen mer komplex och svårtolkad i praktisk användning.\n\nEftersom syftet var att bygga en så **enkel modell som möjligt** utan att förlora alltför mycket precision, var även **modell 2 och 3** mycket relevanta alternativ. Dessa modeller presterade på en jämförbar nivå men med endast tre till fyra prediktorer. Det gjorde dem bättre lämpade för prediktion i ett praktiskt sammanhang där tillgången till variabler kan vara begränsade.\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Saving model to use in undersokning_antaganden.qmd\nsaveRDS(model_3, file = \"model/model_3.rds\")\n```\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n#Saving train data for use in undersokning_antaganden.qmd\nsaveRDS(train, file = \"data/train_ua.rds\")\n```\n\n### Modellens prestanda på testdata\nSom slutlig modell valdes modell 3. Den testades slutligen på tesdtatan.\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\ntest_pred <- predict(model_3, newdata = test)\ntest_rmse <- rmse(test$price, test_pred)\ntest_rmse\n```\n\nDen uppnådde ett RMSE på cirka **139 500 kr**, vilket gav en uppfattning om hur mycket de faktiska priserna i genomsnitt skiljde sig från modellens predikterade värden.\n\nDetta innebar att modellen kan ge en relativt god prisuppskattning, men att osäkerheten ökar vid högre prisklasser, vilket också observerats i tidigare analyser.\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\n# Checking data for expensive cars.\ntrain |> filter(price > 1000000)\nval   |> filter(price > 1000000)\ntest  |> filter(price > 1000000)\n```\n\nEftersom några enstaka bilar i träningsdatan kostade över en miljon kronor, undersöktes om sådana fanns i test- eller valideringsdata. Då inga högprisfordon förekom i testdatan, kan RMSE-värdet underskatta osäkerheten vid prediktion av mycket dyra bilar.\n\n#### Testar modellen med en ny observation\nJag ville nu testa modellens förmåga att prediktera priset för en bil. Jag letade upp en riktig bilannons på blocket och matade in alla värden förutom pris. \n\nBilen hade följande specifikationer:\nBränsle: Diesel\nÅrsmodell: 2018\nMiltal: 14 610\nHästkrafter: 191\nPris i annonsen: 221 800 kr\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\nnew_car <- data.frame(\n  fuel = \"Diesel\",\n  year_model = 2018,\n  miles = 14610,\n  hpower = 191\n)\n```\n\n\n```{r}\n#| echo: false\n#| results: \"hide\"\n#| warning: false\nconfidence_intervals <- predict(model_3, newdata = new_car, interval = \"confidence\", level = 0.95)\nprediction_intervals <- predict(model_3, newdata = new_car, interval = \"prediction\", level = 0.95)\nconfidence_intervals\nprediction_intervals\n```\n\n\n```{r}\n#| echo: false\ndata.frame(\n  Estimate = prediction_intervals[1],\n  CI_Lower = confidence_intervals[2],\n  CI_Upper = confidence_intervals[3],\n  PI_Lower = prediction_intervals[2],\n  PI_Upper = prediction_intervals[3]\n)\n```\n\nPriset i annonsen låg utanför konfidensintervallet men inom prediktionsintervallet, vilket var väntat. Det innebar att priset ligger inom det spann som modellen anser möjligt för enskilda observationer, även om det är något lägre än det förväntade medelvärdet. Den breda spridningen i prediktionsintervallet visade att osäkerheten var större vid enskilda observationer, vilket är normalt i regressionsanalys.\n\n## Diskussion\n### Val av modell och måluppfyllelse\nI arbetet tränades tre modeller med olika antal prediktorer, vilka utvärderades på valideringsdatan. Modell 1 innehöll samtliga tillgängliga prediktorer och hade den högsta förklaringsgraden (adjusted R² ≈ 0,90), medan modell 2 och 3 bestod av färre variabler men uppnådde ändå ett justerat R² kring 0,82.\n\nEftersom målet var att utveckla en så enkel modell som möjligt med bibehållen god förklaringsgrad, valdes modell 3 som slutlig modell. Denna hade fyra prediktorer och bedömdes ge tillräcklig precision samtidigt som den var enklare att använda i praktiken.\n\n### Modellens begränsningar och valda förenklingar\nI modellen har flera faktorer som i verkligheten kan påverka priset valts bort – exempelvis extrautrustning, färg och region. Detta var ett medvetet val i syfte att förenkla modellen och minska brus. Till skillnad från exempelvis bostadsmarknaden, där läge och utseende har stor påverkan, tenderade faktorer som färg eller geografiskt läge inte att vara signifikanta för bilpris i detta dataset. Det kan bero på att bilar är flyttbara och konsumenter är villiga att resa för att köpa rätt bil – därmed påverkade inte platsen priset i samma utsträckning.\n\n### Generaliseringsförmåga och hantering av extrema värden\nFör att förbättra modellens generaliseringsförmåga hade det varit möjligt att:\n\n- Filtrera bort extremt dyra bilar (outliers), vilket skulle ha gjort residualerna mer normalfördelade och minskat osäkerheten vid prediktion.\n\n- Samla in fler observationer av dyrare bilar, vilket hade gett en mer balanserad datamängd och bättre prediktion i de högre prisklasserna.\n\nI detta arbete valdes dock att behålla de extrema värdena. Dels av tidsbrist, men även för att undersöka hur modellen skulle bete sig med sådan data, vilket gav viktiga insikter inför framtida modellering.\n\n### Modellens prestanda och praktisk tillämpning\nModellen presterade bra. På valideringsdatan låg RMSE runt 70 000 kr, och på testdatan ungefär 140 000 kr. Den ökade osäkerheten i testdatan kan bero på att det inte fanns några riktigt dyra bilar där, till skillnad från träningsdatan. Det tyder på att modellen funkar bra för vanliga bilar men får svårare med lyxsegmentet – vilket är rimligt.\n\nFör att testa modellen i praktiken gjordes en prediktion på en riktig annons från Blocket: en dieselbil från 2018 med 14 610 mil och 191 hk. Modellen förutsåg priset till 247 387 kr, jämfört med annonspriset 221 800 kr – en skillnad på ca 25 000 kr. Det får ändå anses vara en träffsäker uppskattning med tanke på marknadens variationer.\n\nSpridningen i prediktionsintervallet förklaras delvis av att datan inte var helt normalfördelad – det fanns några bilar med väldigt höga priser. Jag hade kunnat transformera datan eller ta bort outliers, men valde att behålla dem för att se hur modellen funkar i praktiken även för lite mer extrema priser. Trots detta ger modellen en tillräckligt bra uppskattning, särskilt för vanligare biltyper.\n\n### Sammanfattning\nSyftet var att undersöka om en enkel modell med få prediktorer kunde ge en tillräckligt god förklaring av bilpriser – något som uppnåddes. Genom att gå från en komplex till en praktiskt användbar modell med fyra prediktorer, har arbetet visat att det är möjligt att förenkla utan att förlora allt för mycket precision."},"formats":{"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":true,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","toc":true,"number-sections":true,"include-in-header":["preamble.tex"],"output-file":"resultat.pdf"},"language":{"toc-title-document":"Innehållsförteckning","toc-title-website":"På denna sida","related-formats-title":"Andra Format","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Källa","other-links-title":"Övriga länkar","code-links-title":"Kodlänkar","launch-dev-container-title":"Starta Dev Container","launch-binder-title":"Starta Binder","article-notebook-label":"Artikelanteckningsbok","notebook-preview-download":"Ladda ner anteckningsbok","notebook-preview-download-src":"Ladda ner källkod","notebook-preview-back":"Tillbaka till artikel","manuscript-meca-bundle":"MECA-arkiv","section-title-abstract":"Sammanfattning","section-title-appendices":"Bilagor","section-title-footnotes":"Fotnot","section-title-references":"Referenser","section-title-reuse":"Återanvänd","section-title-copyright":"Copyright","section-title-citation":"Citat","appendix-attribution-cite-as":"Hänvisa till detta arbete som:","appendix-attribution-bibtex":"BibTeX hänvisning:","appendix-view-license":"Visa Licens","title-block-author-single":"Författare","title-block-author-plural":"Författare","title-block-affiliation-single":"Anknuten","title-block-affiliation-plural":"Anknutna","title-block-published":"Utgiven","title-block-modified":"Ändrad","title-block-keywords":"Nyckelord","callout-tip-title":"Tips","callout-note-title":"Notera","callout-warning-title":"Varning","callout-important-title":"Viktigt","callout-caution-title":"Caution","code-summary":"Kod","code-tools-menu-caption":"Kod","code-tools-show-all-code":"Visa all kod","code-tools-hide-all-code":"Göm all kod","code-tools-view-source":"Visa källa","code-tools-source-code":"Källkod","tools-share":"Share","tools-download":"Download","code-line":"Rad","code-lines":"Rader","copy-button-tooltip":"Kopiera till urklipp","copy-button-tooltip-success":"Kopierat!","repo-action-links-edit":"Redigera denna sida","repo-action-links-source":"Visa källa","repo-action-links-issue":"Rapportera ett problem","back-to-top":"Tillbaka till toppen","search-no-results-text":"Inget resultat","search-matching-documents-text":"matchande dokument","search-copy-link-title":"Kopiera länk för att söka","search-hide-matches-text":"Göm ytterligare resultat","search-more-match-text":"annat resultat i detta dokument","search-more-matches-text":"fler resultat i detta dokument","search-clear-button-title":"Rensa","search-text-placeholder":"","search-detached-cancel-button-title":"Avbryt","search-submit-button-title":"Verkställ","search-label":"Sök","toggle-section":"Skifta sektion","toggle-sidebar":"Skifta sidonavigering","toggle-dark-mode":"Skifta mörkt läge","toggle-reader-mode":"Skifta läsläge","toggle-navigation":"Skifta navigering","crossref-fig-title":"Figur","crossref-tbl-title":"Tabell","crossref-lst-title":"Lista","crossref-thm-title":"Teorem","crossref-lem-title":"Lemma","crossref-cor-title":"Följdsats","crossref-prp-title":"Påstående","crossref-cnj-title":"Förmodan","crossref-def-title":"Definition","crossref-exm-title":"Exempel","crossref-exr-title":"Uppgift","crossref-ch-prefix":"Kapitel","crossref-apx-prefix":"Bilaga","crossref-sec-prefix":"Avsnitt","crossref-eq-prefix":"Ekvation","crossref-lof-title":"Figurförteckning","crossref-lot-title":"Tabellförteckning","crossref-lol-title":"Listförteckning","environment-proof-title":"Bevis","environment-remark-title":"Anmärkning","environment-solution-title":"Lösning","listing-page-order-by":"Sorterat efter","listing-page-order-by-default":"Standard","listing-page-order-by-date-asc":"Äldst","listing-page-order-by-date-desc":"Nyast","listing-page-order-by-number-desc":"Högt till lågt","listing-page-order-by-number-asc":"Lågt till högt","listing-page-field-date":"Datum","listing-page-field-title":"Titel","listing-page-field-description":"Beskrivning","listing-page-field-author":"Författare","listing-page-field-filename":"Filnamn","listing-page-field-filemodified":"Ändrad","listing-page-field-subtitle":"Undertitel","listing-page-field-readingtime":"Lästid","listing-page-field-wordcount":"Ordmätning","listing-page-field-categories":"Kategorier","listing-page-minutes-compact":"{0} min","listing-page-category-all":"Allt","listing-page-no-matches":"Inget resultat","listing-page-words":"{0} ord","listing-page-filter":"Filter","draft":"Utkast"},"metadata":{"block-headings":true,"lang":"sv","title":"Resultat och diskussion"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["pdf"]}